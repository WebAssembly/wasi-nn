package wasi:nn

world inference {
    import tensor
    import graph
    import execution
    import errors
}

interface tensor {
    type tensor-dimensions = list<u32>
    type tensor-data = list<u8>

    enum tensor-type {
        fp16,
        fp32,
        bf16,
        up8,
        ip32
    }

    record tensor {
        // Describe the size of the tensor (e.g., 2x2x2x2 -> [2, 2, 2, 2]). To represent a tensor
        // containing a single value, use `[1]` for the tensor dimensions.
        dimensions: tensor-dimensions,

        // Describe the type of element in the tensor (e.g., f32).
        tensor-type: tensor-type,

        // Contains the tensor data.
        data: tensor-data,
    }
}

interface graph {
    use errors.{error}
    type graph-builder = list<u8>
    type graph-builder-array = list<graph-builder>
    use tensor.{tensor}

    type graph = u32

    enum graph-encoding {
        openvino,
        onnx,
        tensorflow,
        pytorch,
        tensorflowlite,
        autodetect,
    }

    enum execution-target {
        cpu,
        gpu,
        tpu
    }

    load: func(builder: graph-builder-array, encoding: graph-encoding, target: execution-target) -> result<graph, error>
    load-named-model: func(name: string) -> result<graph, error>
}

interface execution {
    use errors.{error}
    use tensor.{tensor, tensor-data}
    use graph.{graph}

    type graph-execution-context = u32
    init-execution-context: func(graph: graph) -> result<graph-execution-context, error>
    set-input: func(ctx: graph-execution-context, index: u32, tensor: tensor) -> result<_, error>
    set-input-by-name: func(ctx: graph-execution-context, name: string, tensor: tensor) -> result<_, error>
    compute: func(ctx: graph-execution-context) -> result<_, error>
    get-output: func(ctx: graph-execution-context, index: u32) -> result<list<tensor-data>, error>
    eval: func(tensors: list<tensor>) -> result<list<tensor>, error>
    
}

interface errors {
    enum error {
        // Caller module passed an invalid argument.
        invalid-argument,
        // Invalid encoding.
        invalid-encoding,
        busy,
        // Runtime Error.
        runtime-error,
        // Unsupported operation
        unsupported-operation,
        // Model too large
        model-too-large,
        // Model not found
        model-not-found
    }
}
